@comment{This file has been generated by Pybliographer}

@Article{Huang2006489,
  Author         = "Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew",
  Title          = "Extreme learning machine: Theory and applications ",
  Journal        = "Neurocomputing ",
  Volume         = "70",
  Number         = "1â€“3",
  Pages          = "489 - 501",
  Note           = "Neural NetworksSelected Papers from the 7th Brazilian
                   Symposium on Neural Networks (SBRN '04)7th Brazilian
                   Symposium on Neural Networks ",
  doi            = "https://doi.org/10.1016/j.neucom.2005.12.126",
  issn           = "0925-2312",
  keywords       = "Random node ",
  url            = "http://www.sciencedirect.com/science/article/pii/S0925231206000385",
  year           = 2006
}

@Article{Huang2011,
  Author         = "Huang, Guang-Bin and Wang, Dian Hui and Lan, Yuan",
  Title          = "Extreme learning machines: a survey",
  Journal        = "International Journal of Machine Learning and
                   Cybernetics",
  Volume         = "2",
  Number         = "2",
  Pages          = "107--122",
  abstract       = "Computational intelligence techniques have been used
                   in wide applications. Out of numerous computational
                   intelligence techniques, neural networks and support
                   vector machines (SVMs) have been playing the dominant
                   roles. However, it is known that both neural networks
                   and SVMs face some challenging issues such as: (1) slow
                   learning speed, (2) trivial human intervene, and/or (3)
                   poor computational scalability. Extreme learning
                   machine (ELM) as emergent technology which overcomes
                   some challenges faced by other techniques has recently
                   attracted the attention from more and more researchers.
                   ELM works for generalized single-hidden layer
                   feedforward networks (SLFNs). The essence of ELM is
                   that the hidden layer of SLFNs need not be tuned.
                   Compared with those traditional computational
                   intelligence techniques, ELM provides better
                   generalization performance at a much faster learning
                   speed and with least human intervene. This paper gives
                   a survey on ELM and its variants, especially on (1)
                   batch learning mode of ELM, (2) fully complex ELM, (3)
                   online sequential ELM, (4) incremental ELM, and (5)
                   ensemble of ELM.",
  doi            = "10.1007/s13042-011-0019-y",
  issn           = "1868-808X",
  url            = "http://dx.doi.org/10.1007/s13042-011-0019-y",
  year           = 2011
}

